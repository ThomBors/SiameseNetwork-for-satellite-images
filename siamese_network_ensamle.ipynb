{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\.conda\\envs\\deepL\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm as tq\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imshow\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, modelA, modelB, nb_classes=1):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        # Remove last linear layer\n",
    "        self.modelA.out = nn.Identity()\n",
    "        self.modelB.out = nn.Identity()\n",
    "        \n",
    "        # Create new classifier\n",
    "        self.classifier = nn.Linear(18+18, nb_classes)\n",
    "        \n",
    "    def forward(self, x_l,x_r):\n",
    "        x1 = self.modelA(x_l,x_r)  # clone to make sure x is not changed by inplace methods\n",
    "        #x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = self.modelB(x_l,x_r)\n",
    "        #x2 = x2.view(x2.size(0), -1)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        \n",
    "        x = self.classifier(F.relu(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.apply(self._init_weights)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 5, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(5, 5, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(5,7,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.fc1=nn.Sequential(\n",
    "            nn.Linear(2268,18),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "        self.out = nn.Linear(18,1)\n",
    "        \n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.01)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.normal_(mean=0.5, std=0.01)\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.2)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.normal_(mean=0.5, std=0.01)\n",
    "        \n",
    "    def forward_once(self,inp):\n",
    "        inp=self.conv(inp)\n",
    "        inp=self.fc1(inp)\n",
    "        return inp\n",
    "\n",
    "    def forward(self, inp1, inp2):\n",
    "        out1=self.forward_once(inp1)\n",
    "        out2=self.forward_once(inp2)\n",
    "        dis=torch.abs(out2-out1)\n",
    "        out=self.out(dis)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pretrained torchvision models here\n",
    "modelA = torch.load('../data/net_87',map_location=torch.device('cpu'))\n",
    "modelB = torch.load('../data/net_89',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your separate models\n",
    "# ...\n",
    "\n",
    "\n",
    "# Freeze these models\n",
    "for param in modelA.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "for param in modelB.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "# Create ensemble model\n",
    "model = MyEnsemble(modelA, modelB)\n",
    "x_l = torch.randn(1, 3, 75, 75)\n",
    "x_r = torch.randn(1, 3, 75, 75)\n",
    "output = model(x_l,x_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 4113 examples to work with\n"
     ]
    }
   ],
   "source": [
    "#/content/drive/MyDrive/Colab Notebooks/efficent net/\n",
    "npz = np.load('../data/input_data.npz')\n",
    "X_train = npz['X_train']\n",
    "Y_train = npz['Y_train']\n",
    "\n",
    "del npz\n",
    "\n",
    "print('We have {} examples to work with'.format(Y_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, left_list, right_list,targets, transform):\n",
    "        self.left_dat = left_list\n",
    "        self.right_dat = right_list\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.imag_nomr = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        left_img = self.left_dat[idx]\n",
    "        right_img = self.right_dat[idx]\n",
    "        targets = self.targets[idx]\n",
    "        \n",
    "        left_img = np.transpose(left_img,(2,0,1))\n",
    "        left_img = torch.Tensor(left_img)\n",
    "\n",
    "        right_img = np.transpose(right_img,(2,0,1))\n",
    "        right_img = torch.Tensor(right_img)\n",
    "\n",
    "        # nomalization of immages\n",
    "        left_img = self.imag_nomr(left_img)\n",
    "        right_img = self.imag_nomr(right_img)\n",
    "                        \n",
    "        if self.transform:\n",
    "            left_img = self.transform(left_img)\n",
    "            right_img = self.transform(right_img)\n",
    "    \n",
    "        return left_img, right_img, targets\n",
    "\n",
    "\n",
    "def crate_Pairs_data(image_list,label_list, pairs = 5):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    left_input = []\n",
    "    right_input = []\n",
    "    targets = []\n",
    "\n",
    "    #Number of pairs per image\n",
    "    pairs = pairs\n",
    "    #Let's create the new dataset to train on\n",
    "    for i in range(len(label_list)):\n",
    "        for _ in range(pairs): \n",
    "            # compare the same immage on the left to different immages to the right\n",
    "            compare_to = i \n",
    "            while compare_to == i: #Make sure it's not comparing to itself\n",
    "                compare_to = random.randint(0,len(image_list)-1)\n",
    "\n",
    "            left_img = image_list[i][0]\n",
    "            right_img = image_list[compare_to][0]\n",
    "\n",
    "            # create data sets\n",
    "            left_input.append(np.array(left_img))\n",
    "            right_input.append(np.array(right_img))\n",
    "\n",
    "            if label_list[i] == label_list[compare_to]:# They are the same\n",
    "                targets.append(0.)\n",
    "            else:# Not the same\n",
    "                targets.append(1.)\n",
    "    \n",
    "    return left_input,right_input,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_index, y_index = range(X_train.shape[0]), range(Y_train.shape[0])\n",
    "# test 20% \n",
    "X_train_index, X_test_index, y_train_index, y_test_index = train_test_split(X_index, y_index,\n",
    "    test_size=0.2, shuffle = True, random_state = 42)\n",
    "\n",
    "# validation 20% training 60%\n",
    "X_train_index, X_val_index, y_train_index, y_val_index = train_test_split(X_train_index, y_train_index, \n",
    "    test_size=0.20, random_state= 42) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_test = np.split(X_train[X_test_index],len(X_test_index))\n",
    "label_list_test = np.split(Y_train[y_test_index],len(y_test_index))\n",
    "left_dat,right_dat,targets = crate_Pairs_data(image_list = image_list_test,label_list=label_list_test,pairs=5)\n",
    "test_dataset = CustomImageDataset(left_list=left_dat,right_list=right_dat,targets=targets,transform=None)\n",
    "\n",
    "test_dataset_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=1,shuffle=False, num_workers=2)\n",
    "\n",
    "del image_list_test,label_list_test,test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_out(output,label,TrueNegative,FalseNegative,TruePositive,FalsePositive):\n",
    "    for j in range(output.size(0)):\n",
    "        if (output[j]>0.5) and (label[j]==1):\n",
    "            TrueNegative+=1\n",
    "        elif (output[j]>0.5) and (label[j]==0):\n",
    "            FalseNegative+=1\n",
    "        elif (output[j]<0.5) and (label[j]==0):\n",
    "            TruePositive+=1\n",
    "        elif (output[j]<0.5) and (label[j]==1):\n",
    "            FalsePositive+=1\n",
    "\n",
    "    return TrueNegative,FalseNegative,TruePositive,FalsePositive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "train_on_gpu\n",
    "\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4115 [00:00<?, ?it/s, Accuracy=0]"
     ]
    }
   ],
   "source": [
    "TN=0\n",
    "FN=0\n",
    "TP=1\n",
    "FP=0\n",
    "#del img0, img1, label\n",
    "print(\"Testing...\")\n",
    "bar = tq(test_dataset_loader, postfix={\"Accuracy\":0.0})\n",
    "for img0, img1, label in bar:\n",
    "    \n",
    "    if train_on_gpu:\n",
    "        img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "    \n",
    "    output = model(img0, img1)\n",
    "    \n",
    "    total = label.size(0)\n",
    "    TN,FN,TP,FP = correct_out(output,label,TrueNegative=TN,FalseNegative=FN,TruePositive=TP,FalsePositive=FP)\n",
    "\n",
    "        \n",
    "    Pr = TP / (TP + FP)\n",
    "    Rec = TP /(TP + FN)\n",
    "    Acc = (TP+TN)/(TP + TN + FN + FP)\n",
    "    Jaccard = TP/(TP + FN + FP) \n",
    "    bar.set_postfix(ordered_dict={\"Accuracy\":(Acc)*100})  \n",
    "\n",
    "print('{} correct predictions out of {}\\nAccuracy : {:.2f}\\nJaccard : {:.2f}'.format((TP+TN),(TP+TN+FN+FN), (Acc)*100,Jaccard*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f32311c4dda5146594344329a2ddeb364072fad00719a94f15bc5d46ae24b1c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
